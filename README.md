# Conversational RAG Chatbot (Streamlit + Hugging Face + ChromaDB + Ollama)

## Features
- Upload PDF/TXT documents
- Ingest content into a vector DB (ChromaDB) using Hugging Face sentence-transformers embeddings
- PDF extraction powered by PyMuPDF (fitz)
- Conversational chat about your documents using Ollama (Llama3 model)

## Setup & Usage

### 1. Install Python 3.13+
### 2. Clone this repository

### 3. Install Ollama and pull a Llama model
- Download and install Ollama from https://ollama.com/download
- In your terminal, run: `ollama pull llama3`

### 4. Create and activate a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 5. Install requirements
```bash
pip install -r requirements.txt
```

### 6. Start Ollama and run the Streamlit app
```bash
ollama run llama3
streamlit run app.py
```

### 7. Ingest documents
- Upload PDF/TXT files
- Click "Ingest Documents"

### 8. Chat with the bot
- Type your question and click "Get Answer"

## How it works
- Ingestion: Documents are parsed (PDFs via PyMuPDF/fitz), chunked, embedded (Hugging Face sentence-transformers), stored in ChromaDB
- Query: User question is embedded (Hugging Face sentence-transformers), docs are retrieved, answer generated by Ollama (Llama3 model)

## Troubleshooting
- Make sure `llama-3.2.bin` is present
- If you see ModuleNotFoundError, run `pip install <missing_package>`
- Only PDF/TXT files supported

## Customization
- Change chunk size in `ingest_agent.py`
- Use other embedding models if desired (see Langchain docs)

## Requirements
- Python >=3.13
- streamlit
- pymupdf
- chromadb
- langchain
- langchain-community
- sentence-transformers
- sentence-transformers
# Ollama (https://ollama.com/download)
